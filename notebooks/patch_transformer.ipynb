{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from scipy.stats import boxcox\n",
    "from PIL import Image\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# Set working directory\n",
    "os.chdir(r\"..\") # should be the git repo root directory\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "repo_name = 'net-load-forecasting'\n",
    "assert os.getcwd()[-len(repo_name):] == \"net-load-forecasting\", \"Working directory is not the git repo root directory\"\n",
    "\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch Transformer\n",
    "\n",
    "For 1 minute resolution data it makes sense to patch the data into 15 minute chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.missing_values import extract_subseries\n",
    "\n",
    "\n",
    "class PatchedTimeseriesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, hours_ahead, hours_lookback, patch_n_minutes, stage = 'train', scaler = None ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.freq = None\n",
    "        self.stage = stage\n",
    "        self.scaler = scaler\n",
    "        self.df = self._load_data()\n",
    "        # timeseries interval conversions:\n",
    "        self.freq = infer_frequency(self.df)\n",
    "        self.output_chunk_len = int(hours_ahead * 60 // self.freq)\n",
    "        self.input_chunk_len = int(hours_lookback * 60 // self.freq)\n",
    "        self.patch_len = int(patch_n_minutes // self.freq)\n",
    "\n",
    "        assert hours_ahead * 60 % patch_n_minutes == 0, \"hours ahead must be a multiple of patch size\"\n",
    "        assert hours_lookback * 60 % patch_n_minutes == 0, \"hours lookback must be a multiple of patch size\"\n",
    "        assert stage in ['train', 'val', 'test'], \"stage must be one of 'train', 'val', 'test'\"\n",
    "\n",
    "        self.load_series, self.ts_index = self._setup_data()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.load_series) - self.input_chunk_len - self.output_chunk_len + 1\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # input chunk\n",
    "        input_chunk_index = self.ts_index[idx:idx+self.input_chunk_len]\n",
    "        datetime_encodings_input = self._timenc(input_chunk_index)[::self.patch_len, :]# skip every patch_size\n",
    "        input_chunk_series = self.load_series[idx:idx+self.input_chunk_len].reshape(self.input_chunk_len // self.patch_len, self.patch_len)\n",
    "        input_chunk = np.concatenate([input_chunk_series, datetime_encodings_input], axis=1)\n",
    "\n",
    "        # output chunk\n",
    "        output_chunk_index = self.ts_index[idx+self.input_chunk_len:idx+self.input_chunk_len+self.output_chunk_len]\n",
    "        datetime_encodings_output = self._timenc(output_chunk_index)[::self.patch_len, :]# skip every patch_size\n",
    "        output_chunk_series = self.load_series[idx+self.input_chunk_len:idx+self.input_chunk_len+self.output_chunk_len].reshape(self.output_chunk_len // self.patch_len, self.patch_len)\n",
    "        output_chunk = np.concatenate([output_chunk_series, datetime_encodings_output], axis=1)\n",
    "\n",
    "        return input_chunk, output_chunk\n",
    "\n",
    "\n",
    "    def _timenc(self, ts_index):\n",
    "\n",
    "        # TODO: add option for trigonometric encoding\n",
    "\n",
    "        hour = ts_index.hour / 24\n",
    "        day = ts_index.day / 31\n",
    "        month = ts_index.month / 12\n",
    "        datetime_encodings = np.vstack([hour, day, month]).T\n",
    "        \n",
    "        return datetime_encodings\n",
    "\n",
    "    def _load_data(self):\n",
    "        df = pd.read_hdf(self.data_dir, key='1min/netload')\n",
    "        # getting the frequency of the time series in minutes\n",
    "        return df\n",
    "    \n",
    "    def _setup_data(self):\n",
    "        #make sure that the time series is continuous, i.e. no missing values\n",
    "        # we only want to use the longest continuous subseries\n",
    "        ts = TimeSeries.from_dataframe(self.df, freq = self.freq)\n",
    "        ts_subseries = extract_subseries(ts)\n",
    "        ts_subseries_reviewed = review_subseries(ts_subseries, min_length=(self.input_chunk_len + self.output_chunk_len))[0]\n",
    "\n",
    "        n_subseries = len(ts_subseries_reviewed)\n",
    "\n",
    "        if self.stage == 'train':\n",
    "            self.scaler = MinMaxScaler()\n",
    "            ts_subseries_reviewed = ts_subseries_reviewed[:int(n_subseries*0.8)]\n",
    "            ts = ts_subseries_reviewed[get_longest_subseries_idx(ts_subseries_reviewed)]\n",
    "            values = ts.pd_dataframe().values\n",
    "            values = self.scaler.fit_transform(values)\n",
    "\n",
    "        elif self.stage == 'val':\n",
    "            ts_subseries_reviewed = ts_subseries_reviewed[int(n_subseries*0.8):int(n_subseries*0.9)]\n",
    "            ts = ts_subseries_reviewed[get_longest_subseries_idx(ts_subseries_reviewed)]\n",
    "            values = ts.pd_dataframe().values\n",
    "            values = self.scaler.transform(values)\n",
    "\n",
    "        elif self.stage == 'test':\n",
    "            ts_subseries_reviewed = ts_subseries_reviewed[int(n_subseries*0.9):]\n",
    "            ts = ts_subseries_reviewed[get_longest_subseries_idx(ts_subseries_reviewed)]\n",
    "            values = ts.pd_dataframe().values\n",
    "            values = self.scaler.transform(values)\n",
    "\n",
    "\n",
    "        index = ts.pd_dataframe().index\n",
    "\n",
    "        return values, index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data', 'clean_data', 'data_net_load_forecasting.h5')\n",
    "\n",
    "patch_minutes = 60\n",
    "hours_ahead = 4\n",
    "hours_lookback = 5\n",
    "\n",
    "\n",
    "ds_train = PatchedTimeseriesDataset(data_path, hours_ahead, hours_lookback, patch_minutes, stage = 'train')\n",
    "ds_val = PatchedTimeseriesDataset(data_path, hours_ahead, hours_lookback, patch_minutes, stage = 'val', scaler = ds_train.scaler)\n",
    "ds_test = PatchedTimeseriesDataset(data_path, hours_ahead, hours_lookback, patch_minutes, stage = 'test', scaler = ds_train.scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.patch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(42 + worker_id)\n",
    "\n",
    "class PatchedTimeseriesDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.collate_fn = self.collate_fn_\n",
    "\n",
    "    def collate_fn_(self, batch):\n",
    "        input_chunks, output_chunks = zip(*batch)\n",
    "        input_chunks, output_chunks = np.stack(input_chunks), np.stack(output_chunks)\n",
    "        input_tensor = torch.FloatTensor(input_chunks)\n",
    "        output_tensor = torch.FloatTensor(output_chunks)\n",
    "        return input_tensor, output_tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = PatchedTimeseriesDataLoader(ds_train, batch_size=128, shuffle=True, num_workers=0, worker_init_fn=worker_init_fn)\n",
    "dl_val = PatchedTimeseriesDataLoader(ds_val, batch_size=128, shuffle=False, num_workers=0, worker_init_fn=worker_init_fn)\n",
    "dl_test = PatchedTimeseriesDataLoader(ds_test, batch_size=128, shuffle=False, num_workers=0, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 5, 63]) torch.Size([128, 4, 63])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dl_train:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "class EncoderTransformer(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, hidden_size, d_model, nhead, num_layers, dropout, loss_fn, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, d_model)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, src, trg=None):\n",
    "        src = self.linear(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        src, trg = batch\n",
    "        trg = trg[:, :, :]\n",
    "        output = self(src, trg)\n",
    "        loss = self.loss_fn(output, trg)\n",
    "        #loss = F.mse_loss(output, trg)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        trg = trg[:, :,:1]\n",
    "        output = self(src)\n",
    "        loss = self.loss_fn(output, trg)\n",
    "        self.log('val_loss', loss)\n",
    "        if batch_idx == 0:\n",
    "            buffers = self._plot_predictions(output, trg)\n",
    "            # Combine the image buffers into a single image\n",
    "            images = [np.array(Image.open(buffer)) for buffer in buffers]\n",
    "            combined_image = np.concatenate(images, axis=1)\n",
    "            # Log the combined image to WandB\n",
    "            wandb.log({\"predictions_val_dataset\": wandb.Image(combined_image)})\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        src, trg = batch\n",
    "        trg = trg[:, :, :1]\n",
    "        output = self(src)\n",
    "        loss = self.loss_fn(output, trg)\n",
    "        self.log('test_loss', loss)\n",
    "        if batch_idx == 0:\n",
    "            buffers = self._plot_predictions(output, trg)\n",
    "            # Combine the image buffers into a single image\n",
    "            images = [np.array(Image.open(buffer)) for buffer in buffers]\n",
    "            combined_image = np.concatenate(images, axis=1)\n",
    "            # Log the combined image to WandB\n",
    "            wandb.log({\"predictions_test_dataset\": wandb.Image(combined_image)})\n",
    "        return loss\n",
    "\n",
    "    def _plot_predictions(self, preds, actuals):\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        actuals = actuals.detach().cpu().numpy()\n",
    "        buffers = []\n",
    "        for i in range(5): # plot 5 sequences\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "            # plotting the i-th sequence in the batch\n",
    "            ax.plot(preds[i, :, 0], label='Predictions')\n",
    "            ax.plot(actuals[i, :, 0], label='Actuals')\n",
    "            ax.legend()\n",
    "            # Convert the figure to an image buffer\n",
    "            canvas = FigureCanvas(fig)\n",
    "            buffer = BytesIO()\n",
    "            canvas.print_figure(buffer, format='png')\n",
    "            buffer.seek(0)\n",
    "            # Close the figure to save memory\n",
    "            plt.close(fig)\n",
    "            # Append the image buffer to the list of buffers\n",
    "            buffers.append(buffer)\n",
    "        # Return the list of image buffers\n",
    "        return buffers\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = ds_train.input_chunk_len\n",
    "output_size = ds_train.output_chunk_len\n",
    "hidden_size = x.shape[2]\n",
    "\n",
    "d_model = 64\n",
    "nhead = 4\n",
    "num_layers = 2\n",
    "\n",
    "dropout = 0.1\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model = EncoderTransformer(input_size, output_size, hidden_size, d_model, nhead, num_layers, dropout, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(hidden_size, d_model)\n",
    "\n",
    "q = fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
