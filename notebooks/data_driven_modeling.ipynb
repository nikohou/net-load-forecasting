{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnikolaushouben\u001b[0m (\u001b[33mwattcast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import darts\n",
    "from darts.dataprocessing.transformers.boxcox import BoxCox\n",
    "from darts.models import LightGBMModel, XGBModel, LinearRegressionModel, TFTModel, TransformerModel\n",
    "from darts.metrics import mase, mse, rmse, mae\n",
    "from darts.dataprocessing.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler   \n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from darts.utils.missing_values import extract_subseries\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from wandb.xgboost import WandbCallback\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(r\"..\") # should be the git repo root directory\n",
    "print(\"Current working directory: \" + os.getcwd())\n",
    "repo_name = 'net-load-forecasting'\n",
    "assert os.getcwd()[-len(repo_name):] == \"net-load-forecasting\", \"Working directory is not the git repo root directory\"\n",
    "\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = os.path.join(os.getcwd(),'data','clean_data')\n",
    "model_data_path = os.path.join(os.getcwd(),'data','model_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(config):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Function to load the data for the different model setups.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : Config\n",
    "        Config object with the model setup parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : dict\n",
    "        Dictionary with the data for a specific model setup.\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    df = pd.read_hdf(os.path.join(clean_data_path, \"data_net_load_forecasting.h5\"), key=f\"{config.temp_resolution}min/netload\") / 1e3\n",
    "    df_irr = pd.read_hdf(os.path.join(clean_data_path, \"data_net_load_forecasting.h5\"), key=f\"{config.temp_resolution}min/weather\")\n",
    "    df_irr.rename({'temperature': 'temp_air'}, axis=1, inplace=True)\n",
    "    df_pv_forecast = pd.read_hdf(os.path.join(model_data_path, \"pv_model_results.h5\"), key=f\"{config.temp_resolution}min/pv_forecast_META-{config.META}\") / 1e3\n",
    "\n",
    "    train_end = int(config.train_ratio * len(df))\n",
    "    val_begin = int(config.val_ratio* len(df))\n",
    "\n",
    "\n",
    "    df_train_int = df[:train_end]\n",
    "    df_val_int = df[-val_begin:]\n",
    "    df_test_int = df[-val_begin:]\n",
    "\n",
    "    df_cov_dir_train = df_irr[:train_end]\n",
    "    df_cov_dir_val = df_irr[-val_begin:]\n",
    "    df_cov_dir_test = df_irr[-val_begin:]\n",
    "\n",
    "    df_cov_pv_train = df_pv_forecast[:train_end]\n",
    "    df_cov_pv_val = df_pv_forecast[-val_begin:]\n",
    "    df_cov_pv_test = df_pv_forecast[-val_begin:]\n",
    "\n",
    "    df_train_add = df_train_int + df_cov_pv_train.values\n",
    "    df_train_add[df_train_add < 0] = 0\n",
    "    df_val_add = df_val_int + df_cov_pv_val.values\n",
    "    df_val_add[df_val_add < 0] = 0\n",
    "    df_test_add = df_test_int + df_cov_pv_test.values\n",
    "    df_test_add[df_test_add < 0] = 0\n",
    "\n",
    "    # In this study we are comparing three different model setups: integrated, additive and direct for net load forecasting\n",
    "    model_setups = {\n",
    "                    'integrated': {'target': (df_train_int, df_val_int, df_test_int), 'covs': (df_cov_pv_train, df_cov_pv_val, df_cov_pv_test)},\n",
    "                    'additive': {'target': (df_train_add, df_val_add, df_test_add), 'covs': (None, None, None)},\n",
    "                    'direct': {'target': (df_train_int, df_val_int, df_test_int), 'covs': (df_cov_dir_train, df_cov_dir_val, df_cov_dir_test)}\n",
    "                    }\n",
    "\n",
    "\n",
    "    return model_setups\n",
    "\n",
    "\n",
    "def darts_data_pipeline(config, model_setups):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Function to transform the data into darts.TimeSeries format and apply the data pipeline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : Config\n",
    "\n",
    "    data : dict\n",
    "        Dictionary with the data for the different model setups.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    piped_data : dict\n",
    "        Dictionary with the transformed data for the different model setups.\n",
    "\n",
    "    pipeline : darts.dataprocessing.pipeline.Pipeline\n",
    "        Pipeline object with the data pipeline.\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    data = model_setups[config.model_setup]\n",
    "\n",
    "    df_train, df_val, df_test = data['target']\n",
    "    df_cov_train, df_cov_val, df_cov_test = data['covs']\n",
    "    \n",
    "\n",
    "    # Into Darts format\n",
    "    ts_train = darts.TimeSeries.from_dataframe(df_train, freq=str(config.temp_resolution) + 'min')\n",
    "    ts_train = extract_subseries(ts_train)\n",
    "    ts_val = darts.TimeSeries.from_dataframe(df_val, freq=str(config.temp_resolution) + 'min')\n",
    "    ts_val = extract_subseries(ts_val)\n",
    "    ts_test = darts.TimeSeries.from_dataframe(df_test, freq=str(config.temp_resolution) + 'min')\n",
    "    ts_test = extract_subseries(ts_test)\n",
    "\n",
    "    if config.model_setup == 'additive':\n",
    "        ts_cov_train = None\n",
    "        ts_cov_val = None\n",
    "        ts_cov_test = None\n",
    "    else:\n",
    "        ts_cov_train = darts.TimeSeries.from_dataframe(df_cov_train, freq=str(config.temp_resolution) + 'min')\n",
    "        ts_cov_val = darts.TimeSeries.from_dataframe(df_cov_val, freq=str(config.temp_resolution) + 'min')\n",
    "        ts_cov_test = darts.TimeSeries.from_dataframe(df_cov_test, freq=str(config.temp_resolution) + 'min')\n",
    "\n",
    "    # Reviewing subseries to make sure they are long enough\n",
    "\n",
    "    min_len = config.n_lags + config.n_ahead\n",
    "\n",
    "    ts_train_, ts_cov_train = review_subseries(ts_train, min_len, ts_cov_train)\n",
    "    ts_val_, ts_cov_val = review_subseries(ts_val,  min_len, ts_cov_val)\n",
    "    ts_test_, ts_cov_test = review_subseries(ts_test, min_len, ts_cov_test)\n",
    "\n",
    "\n",
    "\n",
    "    # Load pipeline\n",
    "    pipeline = Pipeline( # missing values have been filled in the 'data_prep.ipynb'\n",
    "                        [\n",
    "                        Scaler(MinMaxScaler()),\n",
    "                        ]\n",
    "                        )\n",
    "    \n",
    "    ts_train_piped = pipeline.fit_transform(ts_train_)\n",
    "    ts_val_piped = pipeline.transform(ts_val_)\n",
    "    ts_test_piped = pipeline.transform(ts_test_)\n",
    "\n",
    "    if config.model_setup == 'additive':\n",
    "        ts_cov_train_piped = None\n",
    "        ts_cov_val_piped = None\n",
    "        ts_cov_test_piped = None\n",
    "\n",
    "    else:  \n",
    "        # Future Covariate Pipeline\n",
    "        pipeline_weather = Pipeline([Scaler(MinMaxScaler())])\n",
    "        ts_cov_train_piped = pipeline_weather.fit_transform(ts_cov_train)\n",
    "        ts_cov_val_piped = pipeline_weather.transform(ts_cov_val)\n",
    "        ts_cov_test_piped = pipeline_weather.transform(ts_cov_test)\n",
    "\n",
    "    # getting the index of the longest subseries, to be used for evaluation later\n",
    "    longest_ts_val_idx = get_longest_subseries_idx(ts_val_piped)\n",
    "    longest_ts_test_idx = get_longest_subseries_idx(ts_test_piped)\n",
    "\n",
    "\n",
    "    piped_data = {'target': (ts_train_piped, ts_val_piped[longest_ts_val_idx], ts_test_piped[longest_ts_test_idx]),\n",
    "                'covs': (ts_cov_train_piped, ts_cov_val_piped, ts_cov_test_piped),\n",
    "                'target_inversed': (ts_train, ts_val[longest_ts_val_idx], ts_test[longest_ts_test_idx])}\n",
    "\n",
    "    return piped_data, pipeline\n",
    "\n",
    "\n",
    "def train_all(config_run):\n",
    "\n",
    "    config = build_config(config_run)\n",
    "    \n",
    "    if config.wandb:\n",
    "        wandb.init(project=\"net-load-forecasting\", name=f\"META-{config.META}_METER-{config.METER}-train_ratio-{config.train_ratio}\")\n",
    "        wandb.config.update(config.data)\n",
    "\n",
    "    predictions_per_model = {}\n",
    "    model_setups_names = config.model_setups_names\n",
    "    eval_set_idx = {'train': 0, 'val': 1, 'test': 2}\n",
    "    for model_setup in model_setups_names:\n",
    "\n",
    "        print(f'Running model setup: {model_setup}')\n",
    "        config.model_setup = model_setup\n",
    "\n",
    "\n",
    "        model_setups_data = load_data(config)\n",
    "        piped_data, pipeline = darts_data_pipeline(config, model_setups_data)\n",
    "        ts_train_piped, ts_val_piped, ts_test_piped = piped_data['target']\n",
    "        ts_cov_train_piped, ts_cov_val_piped, ts_cov_test_piped = piped_data['covs']\n",
    "        trg_train_inversed, trg_val_inversed, trg_test_inversed = piped_data['target_inversed']\n",
    "\n",
    "\n",
    "        print('Training model')\n",
    "        # TODO: replace with patch transformer\n",
    "        model = LightGBMModel(lags=config.n_lags,\n",
    "                        lags_future_covariates= None if config.model_setup == 'additive' else [0],\n",
    "                        add_encoders=config.datetime_encoding   , \n",
    "                        output_chunk_length=config.n_ahead, \n",
    "                        likelihood=None,\n",
    "                        random_state=42\n",
    "                        )\n",
    "\n",
    "        model.fit(ts_train_piped, future_covariates = ts_cov_train_piped)\n",
    "\n",
    "        print('Evaluating on validation set')\n",
    "        predictions, _ = predict_testset(config, model, \n",
    "                                        ts_val_piped, \n",
    "                                        ts_cov_val_piped,\n",
    "                                        pipeline,\n",
    "                                        )\n",
    "        \n",
    "            # subtracting the covariates from the predictions, since we are predicting the net load\n",
    "        if config.model_setup == 'additive':\n",
    "            predictions -= model_setups_data['integrated']['covs'][eval_set_idx[config.evaluation_set]].reindex(predictions.index).values\n",
    "\n",
    "        predictions.columns = ['prediction_'+model_setup]\n",
    "        predictions_per_model[model_setup] = predictions\n",
    "        \n",
    "    if config.evaluation_set == 'val':\n",
    "        persistance = trg_val_inversed.pd_dataframe().shift(config.timesteps_per_hour * 24)\n",
    "    else:\n",
    "        persistance = trg_test_inversed.pd_dataframe().shift(config.timesteps_per_hour * 24)\n",
    "\n",
    "    persistance.columns = ['24h_persistance']\n",
    "    predictions_per_model['24h_persistance'] = persistance\n",
    "\n",
    "\n",
    "    df_metrics = format_and_log_predictions(config, predictions_per_model, trg_val_inversed, trg_test_inversed)\n",
    "\n",
    "    if config.wandb:\n",
    "        wandb.finish()\n",
    "\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "def format_and_log_predictions(config, predictions_per_model, trg_val_inversed, trg_test_inversed):\n",
    "\n",
    "    '''\n",
    "    Evaluates the predictions on the validation set using the evaluation metrics specified in the config.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_compare : pandas.DataFrame\n",
    "        DataFrame with the predictions and the ground truth values.\n",
    "    config : Config\n",
    "        Config object with the model setup parameters.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_metrics : pandas.DataFrame\n",
    "        DataFrame with the evaluation metrics for each model.\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    if config.evaluation_set == 'val':\n",
    "        df_predictions = pd.concat(predictions_per_model.values(), axis=1)\n",
    "        df_compare = pd.merge(trg_val_inversed.pd_dataframe(), df_predictions, left_index=True, right_index=True)\n",
    "    else:\n",
    "        df_predictions = pd.concat(predictions_per_model.values(), axis=1)\n",
    "        df_compare = pd.merge(trg_test_inversed.pd_dataframe(), df_predictions, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "    fig = px.line(df_compare, x=df_compare.index, y=df_compare.columns)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Predictions for {config.evaluation_set} set\",\n",
    "        xaxis_title=\"Time\",\n",
    "        yaxis_title=\"Net Load [kW]\",\n",
    "        legend_title=\"Legend Title\"\n",
    "\n",
    "    )\n",
    "\n",
    "    if config.wandb: \n",
    "        wandb.log({\"predictions\": fig})\n",
    "    else:\n",
    "        fig.show()\n",
    "    \n",
    "\n",
    "    #Metrics for each model\n",
    "    df_gt = df_compare.iloc[:,[0]]\n",
    "    ts_gt = darts.TimeSeries.from_dataframe(df_gt)\n",
    "    df_metrics = pd.DataFrame(index = df_compare.columns[1:], columns = [metric.__name__ for metric in config.eval_metrics])\n",
    "    for col in df_compare.columns[1:]:\n",
    "        ts_pred = darts.TimeSeries.from_dataframe(df_compare[[col]])\n",
    "        for metric in config.eval_metrics:\n",
    "            df_metrics.loc[col, metric.__name__] = metric(ts_gt, ts_pred)\n",
    "\n",
    "    # persistance skill score\n",
    "    rmse_persistence = df_metrics.loc[df_metrics.index == '24h_persistance', 'rmse'][0]\n",
    "    df_metrics['rmse_skill'] = 1 - df_metrics['rmse'] / rmse_persistence\n",
    "    \n",
    "    # imbalance costs\n",
    "    df_imbalance = pd.read_hdf(os.path.join(clean_data_path, \"data_net_load_forecasting.h5\"), key=\"imbalance_price\")\n",
    "    df_compare_energy = df_compare.copy() * (1/config.timesteps_per_hour)\n",
    "    df_metrics['imbalance_costs'] = np.nan\n",
    "    df_gt = df_compare_energy.iloc[:,[0]]\n",
    "    for col in df_compare_energy.columns[1:]:\n",
    "        df_pred = df_compare_energy[[col]]\n",
    "        df_costs = calc_imbalance_costs(df_imbalance, df_gt, df_pred, unit='kWh')\n",
    "        df_metrics.loc[col, 'imbalance_costs'] = df_costs.sum()[0]\n",
    "\n",
    "\n",
    "\n",
    "    if config.wandb:\n",
    "        wandb.log({\"metrics\": wandb.Table(dataframe=df_metrics.reset_index())})\n",
    "\n",
    "    return df_metrics\n",
    "\n",
    "\n",
    "def build_config(config_dataset):\n",
    "\n",
    "    '''\n",
    "    \n",
    "    Takes a config_dataset dictionary and builds a config object from it, deriving the rest of the parameters from the config_dataset.\n",
    "\n",
    "    '''\n",
    "\n",
    "    config = Config().from_dict(config_dataset)\n",
    "    config.temp_resolution = 15 # in minutes\n",
    "    config.horizon_in_hours = 24 + 36 if config.METER == '2' else 36 # in hours, 24 for the data gap in METER-2 and 36 for the day-ahead forecast horizon\n",
    "    config.timestep_encoding = [\"hour\", \"minute\"] if config.temp_resolution == 1 else ['quarter']\n",
    "    config.datetime_encoding =  {\n",
    "                        \"cyclic\": {\"future\": config.timestep_encoding, 'past': config.timestep_encoding}, \n",
    "                        \"position\": {\"future\": [\"relative\",], 'past': [\"relative\",]},\n",
    "                        \"datetime_attribute\": {\"future\": [\"dayofweek\", \"week\"], 'past': [\"dayofweek\", \"week\"]},\n",
    "                } if config.use_datetime_encoding else None\n",
    "\n",
    "    config.timesteps_per_hour = int(60 / config.temp_resolution)\n",
    "    config.n_lags = config.lookback_in_hours * config.timesteps_per_hour\n",
    "    config.n_ahead = config.horizon_in_hours * config.timesteps_per_hour\n",
    "    config.eval_stride = int(np.sqrt(config.n_ahead)) # evaluation stride, how often to evaluate the model, in this case we evaluate every n_ahead steps\n",
    "    \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_imbalance_costs(df_imbalance_price, df_gt, df_pred, unit='MWh'):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Calculates the imbalance costs for a given prediction and ground truth.\n",
    "    First convert power to energy, then multiply by the imbalance price.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_imbalance_price : pandas.DataFrame\n",
    "        DataFrame with the imbalance prices.\n",
    "    df_gt : pandas.DataFrame\n",
    "\n",
    "    df_pred : pandas.DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_costs : pandas.DataFrame\n",
    "        DataFrame with the imbalance costs for each prediction.\n",
    "\n",
    "    '''\n",
    "\n",
    "    unit_dict = {'MWh': 1, 'kWh': 1000, 'Wh': 1000000}\n",
    "\n",
    "    df_comp = pd.merge(df_gt, df_pred, left_index=True, right_index=True, how='inner').dropna()\n",
    "    df_error = (df_comp.iloc[:,0] - df_comp.iloc[:,1]).to_frame('Diff')\n",
    "    df_imbalance_price = df_imbalance_price.reindex(df_error.index)\n",
    "    \n",
    "\n",
    "    df_costs = pd.DataFrame(index=df_imbalance_price.index)\n",
    "    for row in df_imbalance_price.index:\n",
    "        # Regulation state 1\n",
    "        if df_imbalance_price.loc[row, 'Regulation state']==1:\n",
    "        # For GNN\n",
    "            if df_error.loc[row,'Diff']>=0:\n",
    "                if df_imbalance_price.loc[row,'Feed']>=0:\n",
    "                    df_costs.loc[row,'Costs']=df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Feed']\n",
    "                else:\n",
    "                    df_costs.loc[row,'Costs']=df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Feed']\n",
    "            else:\n",
    "                if df_imbalance_price.loc[row,'Consume']>=0:\n",
    "                    df_costs.loc[row,'Costs']=(-1)*df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Consume']\n",
    "                else:\n",
    "                    df_costs.loc[row,'Costs']=(-1)*df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Consume']\n",
    "        # Regulation state -1\n",
    "        elif df_imbalance_price.loc[row, 'Regulation state']==-1:\n",
    "            # For GNN\n",
    "            if df_error.loc[row,'Diff']>=0:\n",
    "                if df_imbalance_price.loc[row,'Feed']>=0:\n",
    "                    df_costs.loc[row,'Costs']=df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Feed']\n",
    "                else:\n",
    "                    df_costs.loc[row,'Costs']=df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Feed']\n",
    "            else:\n",
    "                if df_imbalance_price.loc[row,'Consume']>=0:\n",
    "                    df_costs.loc[row,'Costs']=(-1)*df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Consume']\n",
    "                else:\n",
    "                    df_costs.loc[row,'Costs']=(-1)*df_error.loc[row,'Diff']*df_imbalance_price.loc[row,'Consume']\n",
    "    \n",
    "    return df_costs / unit_dict[unit]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config_run = {\n",
    "'model_setups_names': [\n",
    "                             'additive',\n",
    "                             'integrated',\n",
    "                            'direct'\n",
    "                        ],\n",
    "'model_setup': None,\n",
    "'METER': '1',\n",
    "'META': '1',\n",
    "'train_ratio': 0.8,\n",
    "'val_ratio': 0.1,\n",
    "'lookback_in_hours' : 24,\n",
    "'liklihood': None,\n",
    "'holiday': True,\n",
    "'use_datetime_encoding': True,\n",
    "'boxcox': False,\n",
    "'eval_metrics' : [mae, mse, rmse],\n",
    "'evaluation_set': 'val',\n",
    "'wandb': False,\n",
    "}\n",
    "\n",
    "#df_metrics, df_compare = train_all(config_run)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through all model setups and METER Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-1_METER-2-train_ratio-0.4</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/924cvzlx' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/924cvzlx</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230607_163013-924cvzlx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583ebacf4783483db0651533c22007b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230607_165013-zl5314yk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/zl5314yk' target=\"_blank\">META-1_METER-2-train_ratio-0.6</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/zl5314yk' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/zl5314yk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-1_METER-2-train_ratio-0.6</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/zl5314yk' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/zl5314yk</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230607_165013-zl5314yk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44a72573c6e4873a5ed6600a8874be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666414434, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230607_170826-twmbv42a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/twmbv42a' target=\"_blank\">META-1_METER-2-train_ratio-0.7</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/twmbv42a' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/twmbv42a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-1_METER-2-train_ratio-0.7</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/twmbv42a' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/twmbv42a</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230607_170826-twmbv42a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05417ed80fd4a9486bd05a95647a163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230607_172510-7xgbpwv2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/7xgbpwv2' target=\"_blank\">META-1_METER-2-train_ratio-0.9</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/7xgbpwv2' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/7xgbpwv2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-1_METER-2-train_ratio-0.9</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/7xgbpwv2' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/7xgbpwv2</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230607_172510-7xgbpwv2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "scores_dict_meter = {}\n",
    "ratios = [0.3, 0.4,0.6,0.7, 0.9]\n",
    "\n",
    "\n",
    "for METER in ['1','2']:\n",
    "\n",
    "    scores_dict_train_ratio = {}\n",
    "    for train_ratio in ratios:\n",
    "\n",
    "        config_run = {\n",
    "        'model_setups_names': [\n",
    "                                    'additive',\n",
    "                                    'integrated',\n",
    "                                    'direct'\n",
    "                                ],\n",
    "        'model_setup': None,\n",
    "        'METER': METER,\n",
    "        'META': '1',\n",
    "        'train_ratio': train_ratio,\n",
    "        'val_ratio': 0.1,\n",
    "        'lookback_in_hours' : 24,\n",
    "        'liklihood': None,\n",
    "        'holiday': True,\n",
    "        'use_datetime_encoding': False,\n",
    "        'boxcox': False,\n",
    "        'eval_metrics' : [mae, mse, rmse],\n",
    "        'evaluation_set': 'val',\n",
    "        'wandb': True,\n",
    "        }\n",
    "\n",
    "        df_metrics = train_all(config_run)\n",
    "\n",
    "        scores_dict_train_ratio[train_ratio] = df_metrics\n",
    "\n",
    "    scores_dict_meter[METER] = scores_dict_train_ratio\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_metrics_all = pd.DataFrame()\n",
    "for meter in ['1','2']:\n",
    "    for train_ratio in ratios:\n",
    "        df_metric = scores_dict_meter[meter][train_ratio]\n",
    "        df_metric['METER_SCEN'] = int(meter)\n",
    "        df_metric['train_ratio'] = train_ratio\n",
    "        df_metric.reset_index(inplace=True)\n",
    "        df_metric.rename(columns={'index': 'model_setup'}, inplace=True)\n",
    "        df_metrics_all = df_metrics_all.append(df_metric)\n",
    "\n",
    "\n",
    "str_ratios = ''.join([str(ratio) for ratio in ratios])\n",
    "df_metrics_all.to_csv(os.path.join(os.getcwd(),'data','model_results',f'df_metrics_{str_ratios}.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over different META scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f7d2f86b3146019fc77f1336b7a649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230609_105920-i20m26xl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/i20m26xl' target=\"_blank\">META-1_METER-1-train_ratio-0.9</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/i20m26xl' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/i20m26xl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-1_METER-1-train_ratio-0.9</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/i20m26xl' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/i20m26xl</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230609_105920-i20m26xl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fb503e145c44038c146c7cf4274426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230609_111247-umdmsk19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/umdmsk19' target=\"_blank\">META-2_METER-1-train_ratio-0.9</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/umdmsk19' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/umdmsk19</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-2_METER-1-train_ratio-0.9</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/umdmsk19' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/umdmsk19</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230609_111247-umdmsk19\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cadf8d796a74b3dbc5d1f98bcc1ae60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230609_112555-jc9w9c2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/jc9w9c2v' target=\"_blank\">META-3_METER-1-train_ratio-0.9</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/jc9w9c2v' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/jc9w9c2v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-3_METER-1-train_ratio-0.9</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/jc9w9c2v' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/jc9w9c2v</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230609_112555-jc9w9c2v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3582a9aa53eb4045b6dfd8fed30082c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230609_113905-27n1fkmj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/27n1fkmj' target=\"_blank\">META-4_METER-1-train_ratio-0.9</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/27n1fkmj' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/27n1fkmj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-4_METER-1-train_ratio-0.9</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/27n1fkmj' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/27n1fkmj</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230609_113905-27n1fkmj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5d2869a492414daa1b8be45a4e5a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\nik\\Desktop\\Berkeley_Projects\\net-load-forecasting\\wandb\\run-20230609_115206-usvbbm5f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wattcast/net-load-forecasting/runs/usvbbm5f' target=\"_blank\">META-5_METER-1-train_ratio-0.9</a></strong> to <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wattcast/net-load-forecasting' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/usvbbm5f' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/usvbbm5f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model setup: additive\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: integrated\n",
      "Training model\n",
      "Evaluating on validation set\n",
      "Running model setup: direct\n",
      "Training model\n",
      "Evaluating on validation set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">META-5_METER-1-train_ratio-0.9</strong> at: <a href='https://wandb.ai/wattcast/net-load-forecasting/runs/usvbbm5f' target=\"_blank\">https://wandb.ai/wattcast/net-load-forecasting/runs/usvbbm5f</a><br/>Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230609_115206-usvbbm5f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "scores_dict_meter = {}\n",
    "\n",
    "for META in ['1','2', '3', '4', '5']:\n",
    "\n",
    "    config_run = {\n",
    "    'model_setups_names': [\n",
    "                                'additive',\n",
    "                                'integrated',\n",
    "                                'direct'\n",
    "                            ],\n",
    "    'model_setup': None,\n",
    "    'METER': '1',\n",
    "    'META': META,\n",
    "    'train_ratio': 0.9,\n",
    "    'val_ratio': 0.1,\n",
    "    'lookback_in_hours' : 24,\n",
    "    'liklihood': None,\n",
    "    'holiday': True,\n",
    "    'use_datetime_encoding': False,\n",
    "    'boxcox': False,\n",
    "    'eval_metrics' : [mae, mse, rmse],\n",
    "    'evaluation_set': 'val',\n",
    "    'wandb': True,\n",
    "    }\n",
    "\n",
    "    df_metrics = train_all(config_run)\n",
    "    scores_dict_meter[META] = df_metrics\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_metrics_all = pd.DataFrame()\n",
    "for META in ['1','2', '3', '4', '5']:\n",
    "    df_metric = scores_dict_meter[META]\n",
    "    df_metric['META_SCEN'] = int(META)\n",
    "    df_metric.reset_index(inplace=True)\n",
    "    df_metric.rename(columns={'index': 'model_setup'}, inplace=True)\n",
    "    df_metrics_all = df_metrics_all.append(df_metric)\n",
    "\n",
    "\n",
    "df_metrics_all.to_csv(os.path.join(os.getcwd(),'data','model_results',f'df_metrics_metas.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb Transformer Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TFTModel\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def train_tft():\n",
    "\n",
    "\n",
    "    config_ = build_config(config_run)\n",
    "\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "    config.update(config_.data)\n",
    "\n",
    "    print('config updated')\n",
    "    model_setups_data = load_data(config)\n",
    "    piped_data, pipeline = darts_data_pipeline(config, model_setups_data)\n",
    "    ts_train_piped, ts_val_piped, ts_test_piped = piped_data['target']\n",
    "    ts_cov_train_piped, ts_cov_val_piped, ts_cov_test_piped = piped_data['covs']\n",
    "    trg_train_inversed, trg_val_inversed, trg_test_inversed = piped_data['target_inversed']\n",
    "\n",
    "\n",
    "    optimizer_kwargs = {}\n",
    "    try:\n",
    "        optimizer_kwargs['lr'] = config.lr\n",
    "    except:\n",
    "        optimizer_kwargs['lr'] = 1e-3\n",
    "\n",
    "    pl_trainer_kwargs = {\n",
    "    'max_epochs': 20,\n",
    "    'accelerator': 'gpu',\n",
    "    'devices': [0],\n",
    "    'callbacks': [EarlyStopping(monitor='val_loss', patience=5, mode='min')],\n",
    "    'logger': WandbLogger(log_model='best'),\n",
    "    }\n",
    "\n",
    "    lr_scheduler_kwargs = {\n",
    "        'patience': 2,\n",
    "        'factor': 0.5,\n",
    "        'min_lr': 1e-5,\n",
    "        'verbose': True\n",
    "        }\n",
    "\n",
    "\n",
    "    model = TFTModel(\n",
    "    input_chunk_length=config.n_lags,\n",
    "    output_chunk_length=config.n_ahead,\n",
    "    hidden_size=config.hidden_size,\n",
    "    batch_size=config.batch_size,\n",
    "    lr_scheduler_cls = ReduceLROnPlateau,\n",
    "    lr_scheduler_kwargs = lr_scheduler_kwargs,\n",
    "    optimizer_kwargs = optimizer_kwargs,\n",
    "    pl_trainer_kwargs = pl_trainer_kwargs)\n",
    "    \n",
    "    model.fit(ts_train_piped, future_covariates = ts_cov_train_piped, val_series=ts_val_piped, val_future_covariates =ts_cov_val_piped)\n",
    "\n",
    "    print('Evaluating on validation set')\n",
    "    df_predictions, scores = predict_testset(config, model, \n",
    "                                    ts_val_piped, \n",
    "                                    ts_cov_val_piped,\n",
    "                                    pipeline,\n",
    "                                    )\n",
    "\n",
    "    df_predictions.columns = ['prediction_'+config.model_setup]\n",
    "\n",
    "    df_compare = pd.merge(trg_val_inversed.pd_dataframe(), df_predictions, left_index=True, right_index=True, how = 'left')\n",
    "    fig = px.line(df_compare)\n",
    "\n",
    "\n",
    "    wandb.log({'fig': fig})\n",
    "    wandb.log({'val_rmse': scores['rmse']})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tft()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_setups_names = ['integrated',\n",
    "                        'additive',\n",
    "                        'direct'\n",
    "                      ]\n",
    "\n",
    "config_run = {\n",
    "'model_setup': 'integrated',\n",
    "'METER': '1',\n",
    "'META': '1',\n",
    "'train_ratio': 0.2,\n",
    "'val_ratio' : 0.1,\n",
    "'lookback_in_hours' : 24,\n",
    "'liklihood': None,\n",
    "'holiday': True,\n",
    "'use_datetime_encoding': False,\n",
    "'boxcox': False,\n",
    "#'eval_metrics' : [mae, mse, rmse],\n",
    "'evaluation_set': 'val'\n",
    "}\n",
    "\n",
    "eval_set_idx = {'train': 0, 'val': 1, 'test': 2}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes', #grid, random\n",
    "    'metric': {\n",
    "        'name': 'val_rmse',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'model_setup': {\n",
    "            'values': ['integrated']\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64, 128]\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [3e-4, 1e-3, 1e-4, 1e-5]\n",
    "        },\n",
    "        'full_attention': {\n",
    "            'values': [True, False]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'num_attention_heads': {\n",
    "            'values': [3,4,5,6]\n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [512, 1024, 2048]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"net-load-forecasting\")\n",
    "\n",
    "wandb.agent(sweep_id, function=train_tft, count=1)\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
